---
title: "An Introduction to `classo`"
author: 
  - Younghoon Kim
  - Navonil Deb
  - Sumanta Basu
date: "`r format(Sys.time(), '%B %d, %Y')`"
bibliography: cxreg_refs.bib
link-citations: true
output:
  pdf_document:
    fig_caption: yes
    toc: yes
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{An Introduction to cxreg}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r include=FALSE}
# the code in this chunk enables us to truncate the print output for each
# chunk using the `out.lines` option
# save the built-in output hook
hook_output <- knitr::knit_hooks$get("output")

# set a new output hook to truncate text output
knitr::knit_hooks$set(output = function(x, options) {
  if (!is.null(n <- options$out.lines)) {
    x <- xfun::split_lines(x)
    if (length(x) > n) {
        
      # truncate the output
      x <- c(head(x, n), "....\n")
    }
    x <- paste(x, collapse = "\n")
  }
  hook_output(x, options)
})
```

## Introduction

'cxreg' is a package that fits complex-valued penalized regression models via exact coordinate descent method. Just like a well-known package 'glmnet' [-@friedman2010regularization], the regularization path is computed for the linear regression with lasso penalty, called classo, at a grid of values for the regularization parameter lambda. The package includes methods for prediction an plotting, and functions for cross-validation.

The authors of cxreg are Navonil Deb and Sumanta Basu, with contribution from Younghoon Kim, and the R package is maintained by Younghoon Kim.

This vignette describes basic usage of functions related to classo model in 'cxreg' package in R. There is an original description of the algorithm that should be useful:

* ["Regularized estimation of sparse spectral precision matrices"](https://arxiv.org/abs/2401.11128)

'classo' solves the following problem. For $Y\in\mathbb{Z}^n$ and $X\in\mathbb{Z}^{n \times p}$,

$$
\min_{\beta} \frac{1}{2n} \|Y - X \beta\|_2^2 + \lambda\|\beta\|_1,
$$

over a grid of values of $\lambda$ covering the entire range of possible solutions. Here, since the absolute of complex-values means a complex modulus, $\beta\in\mathbb{Z}^p$ so that the $\ell_1$ penalty can be viewed as

$$
\|\beta\|_1 = \sum_{j=1}^p |\beta_j| = \sum_{j=1}^p\|\Re(\beta_j) + \Im(\beta_j)\|_2,
$$

which is a group Lasso with $p$ groups, each of size 2.


## Installation

Like other R packages on Github, it can be downloaded by the command:

```{r, message=FALSE}
library(devtools)
devtools::install_github("yk748/cxreg")
```


## Quick Start: classo

The purpose of this section is to give users a general sense of the package regarding classo. We will briefly go over the main functions, basic operations and outputs. 'cxreg' can be loaded using the `library` command:

```{r}
library(cxreg)
```

We load a set of data created beforehand for illustration:

```{r}
data(QuickStartExample)
x <- QuickStartExample$x
y <- QuickStartExample$y
```

Note that 'x' is already standardized, which makes the columns in $X$ orthogonal. The advantage of the standardization is described in the original paper [-@deb2024regularized].

We fit the model using the most basic call to 'classo'.

```{r}
fit <- classo(x, y)
```

'fit' is an object of class 'classo' that contains all the relevant information of the fitted model for further use. Various methods are provided for the object such as 'plot', 'coef', and 'predict', just like 'glmnet' package. However, currently 'print' is not provided since the degree of freedom is not computed through the functions.

We can visualize the coefficients by executing the 'plot' method:

```{r}
plot(fit)
```

Each curve corresponds to a variable in complex modulus (i.e., absolute scale). It shows the path of its coefficients in absolute scale against the $\ell$-norm of the whole coefficient vector as $\lambda$ varies. Users may also wish to annotate the curves: this can be done by setting 'label = TRUE' in the plot command.

We can obtain the model coefficients at one or more $\lambda$'s within the range of the sequence:

```{r}
coef(fit, s = 0.1)
```

Users can also make predictions at specific $\lambda$'s with new input data: Note that the third line in the following chunk is about standardization, whose purpose is mentioned above.

```{r}
set.seed(29)
nx <- array(rnorm(5*20), c(5,20)) + (1+1i) * array(rnorm(5*20), c(5,20))
for (j in 1:20) nx[,j] <- nx[,j] / sqrt(mean(Mod(nx[,j])^2))
predict(fit, newx = nx, s = c(0.1, 0.05))
```

The function 'classo' returns a sequence of models for the users to choose from. In many cases, users may prefer the software to select one of them. Cross-validation is perhaps the simplest and most widely used method for that task. 'cv.classo' is the main function to do cross-validation here, along with various supporting methods such as plotting and prediction.

```{r}
cvfit <- cv.classo(x, y)
```

'cv.classo} returns a 'cv.classo' object, a list with all the ingredients of the cross-validated fit.

```{r}
plot(cvfit)
```

This plots the cross-validation curve (red dotted line) along with upper and lower standard deviation curves along the $\lambda$ sequence (error bars). Two special values along the $\lambda$ sequence are indicated by the vertical dotted lines. 'lambda.min' is the value of $\lambda$ that gives minimum mean cross-validated error, while 'lambda.lse' is the value of $\lambda$ that gives the most regularized model such that the cross-validated error is within one standard error of the minimum.

We can use the following code to get the value of 'lambda.min' and the model coefficients at that value of $\lambda$:

```{r}
cvfit$lambda.min
```

```{r}
coef(cvfit, s = "lambda.min")
```

To get the corresponding values at 'lambda.1se', simply replace
'lambda.min' with 'lambda.1se} above, or omit the 's' argument, since
'lambda.1se' is the default.

Note that unlike 'glmnet' package, the coefficients are not represented in sparse matrix format, rather they are in the dense format. This is because of the traits of complex values in the function.

Predictions can be made based on the fitted 'cv.glmnet' object as well. The code below gives predictions for the new input matrix 'newx' at 'lambda.min':

```{r eval=FALSE}
predict(cvfit, newx = x[1:5,], s = "lambda.min")
```

This concludes the basic usage of `classo`.

